{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "target = pd.read_csv(\"test_public.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "      <th>subject_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vUXizsqexyZVRdFH</td>\n",
       "      <td>因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>影响</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4QroPd9hNfnCHVt7</td>\n",
       "      <td>四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QmqJ2AvM5GplaRyz</td>\n",
       "      <td>斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>低</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KMT1gFJiU4NWrVDn</td>\n",
       "      <td>这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>有钱任性</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nVIlGd5yMmc37t1o</td>\n",
       "      <td>17价格忒高，估计也就是14-15左右。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content_id                                            content  \\\n",
       "0  vUXizsqexyZVRdFH           因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。   \n",
       "1  4QroPd9hNfnCHVt7      四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。   \n",
       "2  QmqJ2AvM5GplaRyz  斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...   \n",
       "3  KMT1gFJiU4NWrVDn           这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了   \n",
       "4  nVIlGd5yMmc37t1o                            17价格忒高，估计也就是14-15左右。      \n",
       "\n",
       "  subject  sentiment_value sentiment_word  subject_no  \n",
       "0      价格                0             影响           0  \n",
       "1      价格               -1              高           0  \n",
       "2      价格                1              低           0  \n",
       "3      价格               -1           有钱任性           0  \n",
       "4      价格               -1              高           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode label\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train['subject'])\n",
    "train.loc[:,'subject_no'] = pd.Series(le.transform(train['subject']), index=train.index)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_dump(train_df):\n",
    "    train_dict = {}\n",
    "    for ind, row in train_df.iterrows():\n",
    "        content, label = row['content'], row['label']\n",
    "        if train_dict.get(content) is None:\n",
    "            train_dict[content] = {label}\n",
    "        else:\n",
    "            train_dict[content].add(label)\n",
    "    \n",
    "    conts = []\n",
    "    labels = []\n",
    "    for k, v in train_dict.items():\n",
    "        conts.append(k)\n",
    "        labels.append(v)\n",
    "    return conts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'价格1', '配置1'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'] = train['subject'].str.cat(train['sentiment_value'].astype(str))\n",
    "train_contents, train_labels = clean_dump(train)\n",
    "train_labels[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "subject_onehot = mlb.fit_transform(train_labels)\n",
    "subject_onehot[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.616 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9947 128\n",
      "2364 127\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "content_col = train['content'].apply(lambda x: [word for word in jieba.cut(x)])\n",
    "content_col_tar = target['content'].apply(lambda x: [word for word in jieba.cut(x)])\n",
    "train.loc[:, 'content_words'] = pd.Series([\" \".join(words) for words in content_col], index=train.index)\n",
    "target.loc[:, 'content_words'] = pd.Series([\" \".join(words) for words in content_col_tar], index=target.index)\n",
    "# content shape\n",
    "print(len(content_col), max([len(x) for x in content_col]))\n",
    "print(len(content_col_tar), max([len(x) for x in content_col_tar]))\n",
    "max_length=max([len(x) for x in content_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for words in content_col.values:\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "for words in content_col_tar.values:\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "encoded_train = [one_hot(d, vocab_size) for d in train['content_words'].values]\n",
    "encoded_target = [one_hot(d, vocab_size) for d in target['content_words'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_target = pad_sequences(encoded_target, maxlen=max_length, padding='post')\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Flatten, Dense, Embedding, Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense\n",
    "from keras.layers import Input, Dense, Masking, LSTM, Bidirectional\n",
    "\n",
    "OUTPUT_SIZE = 10\n",
    "CELL_SIZE = 50\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "epoche = 100 # 训练100轮\n",
    "\n",
    "# define the model 定义模型\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(LSTM(CELL_SIZE, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "# optimizer\n",
    "model.compile(optimizer='adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "# summarize the model 打印模型信息\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "X_train, y_train = padded_train, subject_onehot\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train,\n",
    "  epochs=epoche,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  validation_split=0.2,\n",
    "  verbose=1, callbacks=callbacks_list,\n",
    "          class_weight= class_weights\n",
    "  )\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "doc_predicted = model.predict(padded_target)\n",
    "prdc= enc.inverse_transform(doc_predicted).reshape(len(content_col_tar))\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "submit = pd.DataFrame(columns=['content_id'])\n",
    "submit['content_id']=target['content_id']\n",
    "submit['subject'] = pd.Series(le.inverse_transform(prdc), index=target.index)\n",
    "submit['sentiment_value'] = 0\n",
    "submit['sentiment_word'] = \"\"\n",
    "submit.to_csv(\"submit.csv\", index=False)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
